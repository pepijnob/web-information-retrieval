{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import nltk\n",
    "import pandas as pd\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "df = pd.read_csv('song.csv',header = None) \n",
    "df.columns = ['artist', 'song' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bash.n.02'),\n",
       " Synset('do.n.02'),\n",
       " Synset('doctor_of_osteopathy.n.01'),\n",
       " Synset('make.v.01'),\n",
       " Synset('perform.v.01'),\n",
       " Synset('do.v.03'),\n",
       " Synset('do.v.04'),\n",
       " Synset('cause.v.01'),\n",
       " Synset('practice.v.01'),\n",
       " Synset('suffice.v.01'),\n",
       " Synset('do.v.08'),\n",
       " Synset('act.v.02'),\n",
       " Synset('serve.v.09'),\n",
       " Synset('do.v.11'),\n",
       " Synset('dress.v.16'),\n",
       " Synset('do.v.13')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return None\n",
    " \n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    " \n",
    "    try:\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "\n",
    "\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    " \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    " \n",
    "    score, count = 0.0, 0\n",
    "\n",
    " \n",
    "    # For each word in the first sentence\n",
    "    #for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        #best_score = max([synset.path_similarity(ss) for ss in synsets2])\n",
    "    arr_simi_score = []\n",
    "    for syn1 in synsets1:\n",
    "        for syn2 in synsets2:\n",
    "            simi_score = syn1.wup_similarity(syn2)\n",
    "\n",
    " \n",
    "        # Check that the similarity could have been computed\n",
    "            if simi_score is not None:\n",
    "                arr_simi_score.append(simi_score)\n",
    "                best = max(arr_simi_score)\n",
    "                score += best\n",
    "                count += 1\n",
    "            #if best is not None:\n",
    "            #    score += best\n",
    "             #   count += 1\n",
    " \n",
    "    # Average the values\n",
    "    if count != 0:\n",
    "        score /= count\n",
    "\n",
    "\n",
    "    return score\n",
    "\n",
    "def symmetric_sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the symmetric sentence similarity using Wordnet \"\"\"\n",
    "    return (sentence_similarity(sentence1, sentence2) + sentence_similarity(sentence2, sentence1)) / 2\n",
    "\n",
    "sentences = []\n",
    "for x in range(1000):\n",
    "    sentences = sentences + [df['song'][x]]\n",
    " \n",
    "\n",
    "    #print (\"Similarity(\\\"%s\\\", \\\"%s\\\") = %s\" % (sentence, focus_sentence, sentence_similarity(sentence, focus_sentence)))\n",
    "    \n",
    "\n",
    "# similarity(\"Cats are beautiful animals.\", \"Dogs are awesome.\") = 0.511111111111\n",
    "# Similarity(\"Dogs are awesome.\", \"Cats are beautiful animals.\") = 0.666666666667\n",
    " \n",
    "# Similarity(\"Cats are beautiful animals.\", \"Some gorgeous creatures are felines.\") = 0.833333333333\n",
    "# Similarity(\"Some gorgeous creatures are felines.\", \"Cats are beautiful animals.\") = 0.833333333333\n",
    " \n",
    "# Similarity(\"Cats are beautiful animals.\", \"Dolphins are swimming mammals.\") = 0.483333333333\n",
    "# Similarity(\"Dolphins are swimming mammals.\", \"Cats are beautiful animals.\") = 0.4\n",
    " \n",
    "# Similarity(\"Cats are beautiful animals.\", \"Cats are beautiful animals.\") = 1.0\n",
    "# Similarity(\"Cats are beautiful animals.\", \"Cats are beautiful animals.\") = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_search(query):\n",
    "    focus_sentence = query\n",
    "    rank = []\n",
    "    result = ()\n",
    "    result2 = ()\n",
    "    index = 0\n",
    "    floatrank = np.asarray(rank, dtype = np.float32)\n",
    "    floatrank2 = np.asarray(rank, dtype = np.float32)\n",
    "    for sentence in sentences:\n",
    "        similarity = symmetric_sentence_similarity(focus_sentence, sentence)\n",
    "        #print (\"Similarity(\\\"%s\\\", \\\"%s\\\") = %s\" % (focus_sentence, sentence, similarity))\n",
    "        if similarity > 0.8:\n",
    "            result = result + (sentence, similarity)\n",
    "            floatrank = np.asarray(similarity)\n",
    "            floatrank2 =  np.append(floatrank2, floatrank)\n",
    "            result2 = result2 + (index,)\n",
    "        index += 1\n",
    "    print(result)\n",
    "    print(result2)\n",
    "    for x in range(len(result2)):\n",
    "        print(df['artist'][(result2[x])] + \" \" + df['song'][(result2[x])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Green Light', 1.0, 'Moonlight', 0.9565217391304348, 'Moonlight', 0.9565217391304348, 'New Light', 1.0, 'All of the Lights', 1.0, 'Starlight', 0.9565217391304348, 'The Light Is Coming (feat. Nicki Minaj)', 1.0, 'Sunshine of Your Love', 0.9565217391304348, 'Light On', 1.0)\n",
      "(114, 193, 220, 378, 390, 595, 717, 737, 955)\n",
      "Lorde Green Light\n",
      "Foals Moonlight\n",
      "xxxtentacion Moonlight\n",
      "John Mayer New Light\n",
      "Kanye West All of the Lights\n",
      "Muse Starlight\n",
      "Ariana Grande The Light Is Coming (feat. Nicki Minaj)\n",
      "Cream Sunshine of Your Love\n",
      "Maggie Rogers Light On\n"
     ]
    }
   ],
   "source": [
    "last_search('light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ariana Grande'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
