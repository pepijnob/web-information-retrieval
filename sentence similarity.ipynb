{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages needed\n",
    "# wordnet of NLTK wordnet (Princeton, 2010) -> large lexical database including nouns, verbs, adjectives and adverbs. \n",
    "#\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import nltk\n",
    "import pandas as pd\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data from a csv file\n",
    "df = pd.read_csv('song_artist.csv',header = None) \n",
    "df.columns = ['artist', 'song' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example of a synset(set of 'cognitive synonyms'): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bash.n.02'),\n",
       " Synset('do.n.02'),\n",
       " Synset('doctor_of_osteopathy.n.01'),\n",
       " Synset('make.v.01'),\n",
       " Synset('perform.v.01'),\n",
       " Synset('do.v.03'),\n",
       " Synset('do.v.04'),\n",
       " Synset('cause.v.01'),\n",
       " Synset('practice.v.01'),\n",
       " Synset('suffice.v.01'),\n",
       " Synset('do.v.08'),\n",
       " Synset('act.v.02'),\n",
       " Synset('serve.v.09'),\n",
       " Synset('do.v.11'),\n",
       " Synset('dress.v.16'),\n",
       " Synset('do.v.13')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm we use is based on the algorithm proposed by \n",
    "# Mihalcea et al. in the paper “Corpus-based and Knowledge-based Measures of Text Semantic Similarity” (https://www.aaai.org/Papers/AAAI/2006/AAAI06-123.pdf)\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    #Convert a Penn Treebank tag to a simplified Wordnet tag\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    "    \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "\n",
    " \n",
    "    return None\n",
    " \n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    " \n",
    "    try:\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "   #compute the sentence similarity using Wordnet\n",
    "\n",
    "\n",
    "    # Tokenize the word individually and tag them\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    " \n",
    "    # Get the synsets for each tagged word\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    " \n",
    "    score, count = 0.0, 0\n",
    "\n",
    " \n",
    "    # For each word in the first sentence\n",
    "    #for synset in synsets1:\n",
    "    # Get the similarity value of the most similar word in the other sentence\n",
    "        \n",
    "    arr_simi_score = []\n",
    "    for syn1 in synsets1:\n",
    "        for syn2 in synsets2:\n",
    "            simi_score = syn1.wup_similarity(syn2)\n",
    "\n",
    " \n",
    "        # Check that the similarity could have been computed\n",
    "            if simi_score is not None:\n",
    "                arr_simi_score.append(simi_score)\n",
    "                best = max(arr_simi_score)\n",
    "                score += best\n",
    "                count += 1\n",
    " \n",
    "    # values average\n",
    "    if count != 0:\n",
    "        score /= count\n",
    "\n",
    "\n",
    "    return score\n",
    "\n",
    "def symmetric_sentence_similarity(sentence1, sentence2):\n",
    "    #compute the symmetric sentence similarity using Wordnet\n",
    "    # this means: first compute the sentence similarity of the query to the songtitle and then the similarity between\n",
    "    # the songtitle and the query, lastly , dividing the total by 2\n",
    "    return (sentence_similarity(sentence1, sentence2) + sentence_similarity(sentence2, sentence1)) / 2\n",
    "\n",
    "#save songs in variable\n",
    "sentences = []\n",
    "for x in range(1000):\n",
    "    sentences = sentences + [df['song'][x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_search(query):\n",
    "    focus_sentence = query\n",
    "    rank = []\n",
    "    result = ()\n",
    "    result2 = ()\n",
    "    index = 0\n",
    "    floatrank = np.asarray(rank, dtype = np.float32)\n",
    "    floatrank2 = np.asarray(rank, dtype = np.float32)\n",
    "    for sentence in sentences:\n",
    "        similarity = symmetric_sentence_similarity(focus_sentence, sentence)\n",
    "        #print (\"Similarity(\\\"%s\\\", \\\"%s\\\") = %s\" % (focus_sentence, sentence, similarity))\n",
    "        if similarity > 0.8:\n",
    "            result = result + (sentence, similarity)\n",
    "            floatrank = np.asarray(similarity)\n",
    "            floatrank2 =  np.append(floatrank2, floatrank)\n",
    "            result2 = result2 + (index,)\n",
    "        index += 1\n",
    "    print(result)\n",
    "    print(result2)\n",
    "    for x in range(len(result2)):\n",
    "        print(df['artist'][(result2[x])] + \"-\" + df['song'][(result2[x])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example result of the algorithm with query 'light':\n",
    "\n",
    "giving first the name of the song and the similarity according to the algorithm(on a scale of 0 to 1)\n",
    "\n",
    "Second, the index of the song/artist in the dataset\n",
    "\n",
    "Last, The artist and song name\n",
    "\n",
    "small evaluation by some examples below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Green Light', 1.0, 'Moonlight', 0.9565217391304348, 'Moonlight', 0.9565217391304348, 'New Light', 1.0, 'All of the Lights', 1.0, 'Starlight', 0.9565217391304348, 'The Light Is Coming (feat. Nicki Minaj)', 1.0, 'Sunshine of Your Love', 0.9565217391304348, 'Light On', 1.0)\n",
      "(114, 193, 220, 378, 390, 595, 717, 737, 955)\n",
      "Lorde-Green Light\n",
      "Foals-Moonlight\n",
      "xxxtentacion-Moonlight\n",
      "John Mayer-New Light\n",
      "Kanye West-All of the Lights\n",
      "Muse-Starlight\n",
      "Ariana Grande-The Light Is Coming (feat. Nicki Minaj)\n",
      "Cream-Sunshine of Your Love\n",
      "Maggie Rogers-Light On\n"
     ]
    }
   ],
   "source": [
    "last_search('light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pink + White', 0.875, 'Big Blue', 1.0, 'Bodak Yellow', 0.875, 'Blue Jeans', 1.0, 'Brown Eyed Girl', 0.875, 'Blue Monday - 2016 Remastered Version', 1.0)\n",
      "(86, 379, 399, 450, 697, 733)\n",
      "Frank Ocean-Pink + White\n",
      "Vampire Weekend-Big Blue\n",
      "Cardi B-Bodak Yellow\n",
      "Lana Del Rey-Blue Jeans\n",
      "Van Morrison-Brown Eyed Girl\n",
      "New Order-Blue Monday - 2016 Remastered Version\n"
     ]
    }
   ],
   "source": [
    "last_search('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Happier', 1.0, 'You Seemed so Happy', 0.85, 'Happier', 1.0)\n",
      "(45, 958, 998)\n",
      "Marshmello-Happier\n",
      "The Japanese House-You Seemed so Happy\n",
      "Ed Sheeran-Happier\n"
     ]
    }
   ],
   "source": [
    "last_search('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dance to This (feat. Ariana Grande)', 1.0, 'I Wanna Dance with Somebody (Who Loves Me)', 0.9133333333333333, 'Just Dance', 1.0, 'One Dance', 1.0, 'Shut Up and Dance', 1.0, 'Dance, Dance', 1.0)\n",
      "(268, 396, 468, 471, 604, 609)\n",
      "Troye Sivan-Dance to This (feat. Ariana Grande)\n",
      "Whitney Houston-I Wanna Dance with Somebody (Who Loves Me)\n",
      "Lady Gaga-Just Dance\n",
      "Drake-One Dance\n",
      "Walk the Moon-Shut Up and Dance\n",
      "Fall Out Boy-Dance, Dance\n"
     ]
    }
   ],
   "source": [
    "last_search('dance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# shows no results , nothing is similar enough to sky in our database\n",
    "last_search('sky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "#as '0' is not an actual word it won't return anyting, however, 'zero' does.\n",
    "last_search('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Nothing Else Matters', 1.0, \"There's Nothing Holdin' Me Back\", 1.0)\n",
      "(249, 663)\n",
      "Metallica-Nothing Else Matters\n",
      "Shawn Mendes-There's Nothing Holdin' Me Back\n"
     ]
    }
   ],
   "source": [
    "last_search('zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "last_search('what about an actual sentence?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Do I Wanna Know?', 1.0, \"Don't Stop Me Now - Remastered\", 1.0, 'Make Up', 1.0, \"Don't Call Me Up\", 1.0, 'Who Do You Love (with 5 Seconds of Summer)', 1.0, \"Don't Stop Believin'\", 1.0, 'Look What You Made Me Do', 0.84375, \"It's Not Living (If It's Not with You)\", 0.90625, 'Make Me Feel', 1.0, 'Love It If We Made It', 0.8125, \"(Don't Fear) The Reaper\", 1.0, \"Boys Don't Cry\", 0.9333333333333333, \"Don't Speak\", 1.0, 'Oops!...I Did It Again', 1.0, 'You Make My Dreams', 1.0, 'Sorry Not Sorry', 0.9166666666666667, 'I Did Something Bad', 1.0, \"Hips Don't Lie\", 0.9351851851851851, \"Don't You (Forget About Me)\", 1.0, \"I'm Not Okay (I Promise)\", 0.8928571428571428, \"What I've Done\", 1.0, \"Don't You Want Me\", 1.0, \"I'm Not the Only One\", 0.8928571428571428, \"Don't Stop the Music\", 1.0)\n",
      "(23, 31, 47, 71, 175, 185, 221, 294, 331, 339, 354, 392, 438, 475, 488, 582, 588, 608, 615, 646, 730, 735, 836, 976)\n",
      "Arctic Monkeys-Do I Wanna Know?\n",
      "Queen-Don't Stop Me Now - Remastered\n",
      "Ariana Grande-Make Up\n",
      "Mabel-Don't Call Me Up\n",
      "The Chainsmokers-Who Do You Love (with 5 Seconds of Summer)\n",
      "Journey-Don't Stop Believin'\n",
      "Taylor Swift-Look What You Made Me Do\n",
      "The 1975-It's Not Living (If It's Not with You)\n",
      "Janelle Monáe-Make Me Feel\n",
      "The 1975-Love It If We Made It\n",
      "Blue Öyster Cult-(Don't Fear) The Reaper\n",
      "The Cure-Boys Don't Cry\n",
      "No Doubt-Don't Speak\n",
      "Britney Spears-Oops!...I Did It Again\n",
      "Hall & Oates-You Make My Dreams\n",
      "Demi Lovato-Sorry Not Sorry\n",
      "Taylor Swift-I Did Something Bad\n",
      "Shakira-Hips Don't Lie\n",
      "Simple Minds-Don't You (Forget About Me)\n",
      "My Chemical Romance-I'm Not Okay (I Promise)\n",
      "Linkin Park-What I've Done\n",
      "The Human League-Don't You Want Me\n",
      "Sam Smith-I'm Not the Only One\n",
      "Rihanna-Don't Stop the Music\n"
     ]
    }
   ],
   "source": [
    "last_search('does not always perform well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
